---
title: "Information Retrieval(7)"
categories:
    - Information Retrieval
tags:
    - Information Retrieval
date: 2023-10-27
toc: true
---

Ranked Information Retriveval을 위한 score 기준/Vector Space Model/tf-idf weight/query-document match score기준/

### Boolean Search의 문제

- 너무 많은 검색결과를 도출

- Document either match or don’t

- Ranked result 반환하는 것 원칙적으로 불가능

- User가 알아서 적절한 수의 검색결과가 도출될 수 있도록 query를 작성하는 skill 이 필요함(가장 큰 문제)

**→ 해결: Scoring**

### Scoring

- 사용자에게 usefulness한 document를 우선적으로 반환

- 반환되는 결과가 많아도 ranked retrieval을 하면 괜찮음

- [0,1] → 0과 1 사이의 실수로 각 document에 score을 부여

- score의 기준은 그 document가 사용자의 query와 얼마나 일치하는지임

    - (query, document) pair

#### 1. TF를 기준으로 score을 부여

- 문서에 query에 등장하는 term의 빈도 수가 높으면 더 높은 score을 부여

- 예) 만약 query:car 인 경우

    - car 단어가 한 번도 등장하지 않은 document 1: 0

    - car 단어가 5번 등장한 document: 0.1

    - car 단어가 10번 등장한 document: 0.2

- 앞서 보았듯 이런 TF를 기준으로 score 부여 방식에는 문제가 있음

    - 10 times in 1000 pages VS 5 times in 10 pages

    - 단순히 TF로 ranked 결과를 반환하기에는 애매

**→ 해결: Jaccard Coefficient**

### Jaccard Coefficient

- scoring을 하는 또 다른 방식

- 문서 A와 문서 B의 겹치는 정도를 통해 scoring을 진행

    
    > Jaccard(A,B) = |A∩B| / |A∪B|

    
    - ex) Jaccard(A,A) = 1

    - ex) Jaccard(A,B) = 0 if A∩B = 0 → A와 B가 서로 겹치는 부분이 아예 없는 경우

- 문서들끼리는 사이즈가 같지 않아도 됨

- 이런 방식을 이용해 query와 document의 match score을 측정 → **Query-Document Match Score**

![image](https://github.com/dareunk/dareunk.github.io/assets/83913407/f9e572ef-c6e5-4688-8ffb-da56fdf3d42a)

- Jaccard의 계수가 클수록 그 document와 query와의 유사도가 더 큰 것 → 부합

#### [ 문제 ]

- Jaccard Coefficient는 TF와 DF을 고려하지 않음

- Jaccard Coefficient는 문서들의 겹치는 정도

- TF는 한 문서에서 그 term이 나오는 빈도수, DF는 전체 문서에서 그 term을 가지고 있는 문서의 수

### Vector Space Model

#### [ Bag of Words Model ]

- vector model에서는 document안에서 단어들 순서 상관없음

    - John is quicker then Mary와  Mary is quicker than John 이 vector space model에서는 같음

    - ↔ positional index에서는 이것들이 구별되어 있음

- bigram이나 trigram을 통해 문장을 추출 → 이때 정확도로 따지면 trigram이 더 높으나, trigram은 bigram에 비해 더 많은 경우의 수를 가지고 있어, bigram을 많이 사용

    - 이때 많이 나오는 빈도수 높은 bigram을 통해 사용자의 query와 비교하여 error을 파악

    - 어떤 문장이 더 일반적으로 사용되는지를 파악할 수 있음

![image](https://github.com/dareunk/dareunk.github.io/assets/83913407/4ad99c77-99fa-4c22-baff-fb93f6d87086)


**In term-document Matrix**

![image](https://github.com/dareunk/dareunk.github.io/assets/83913407/cd480ea5-fbe5-4a2b-abf6-f4b63b800538)

- Antony and Cleopatra <157,4,232,0,57,2,2>

- Dictionary size = V

- Each document is a vector in N^|v|

    - vector의 사이즈는 dictionary size(vocabulary)와 일치

- |V|-dimensional vector space

    - 정보검색에서는 V가 굉장히 크기 때문에 dimesion이 굉장히 큼

    - ex) vocabulary = 40 → 실제로는 100만개 이상으로 구성(web search engine)

    - documents은 dimension이 40인 공간에 점들로 표현됨

- in term-document matrix에서는 incidence vector들이 대부분 0 → sparse vector

#### [ Term Frequency ]

- the number of times of that t occurs in d

![image](https://github.com/dareunk/dareunk.github.io/assets/83913407/9b76406f-64d7-4122-bda4-fb429b83fd19)

- query-document match scores로 TF이용

- raw term frequency

    - score의 기준으로 쓰기에는 좋지 않음

    - 이유: 실제 그 query와 document간의 유사도는 TF와 비례적으로 증가하지 않음

    - ex) 10 times in 1000 pages VS 5 times in 10 pages

- log tf_t,d 를 이용 → TF에 log 붙임

#### [ Document Frequency ]

**df_t(≤N)**

- DF는 그 term의 informativeness의 측정 기준이 됨

- 문서집합에 적게 등장하는 단어가 더 informative 함(더 precision) ↔ stop word

- frequent terms에 대해서는 stop words에 대한 recall 가능성이 높음

- rare terms들을 가진 document는 그 rare term을 가진 query와의 유사도가 더 높음
    
    → 따라서 rare terms에 더 높은 가중치(weight)을 줌
    
- rare terms들은 strong indicator of relevance.

- ex) query: arachnocentric → arachnocentric을 가진  document와의 유사도 높음

- DF가 낮음 → rare terms → 더 높은 가중치

- DF가 높음 → frequent terms → 더 낮은 가중치

    - DF가 높다고 가중치를 0으로 설정할 수는 없음!

    - 그러면 단어가 아예 포함이 안 된 문서와 같아지기 때문에

    - 어느정도의 가중치는 주되 그 값을 적게 줘야함


- DF는 query-document와의 match를 측정할 때(가중치) 반비례 관계

- idf_t = log N/df_t

### [ tf - idf weight ]

![image](https://github.com/dareunk/dareunk.github.io/assets/83913407/dbb5bfc8-65b3-462a-9549-262ada097ff6)

- tf는 0이 될 수 있지만, df는 0이 될 수 없음

    - 그 term이 나온 문서가 하나도 없다면 그 term은 dictionary에 있지 않음

    - 한 문서는 a라는 term을 안 가지고 있을 수 있음(in term-document matrix)

- 따라서 tf는 1일 때 log1는 0이므로 기존의 term이 아예 나오지 않은 document와의 구분을 위해서 다음과 같이 구분

![image](https://github.com/dareunk/dareunk.github.io/assets/83913407/9b76406f-64d7-4122-bda4-fb429b83fd19)

- tf-idf weight는 가장 좋은 weight scheme임

#### [ query도 vector ! ]

- 사용자가 입력한 query도 시스템 내부에서 자동적으로 vector로 변환

- query-document match score 기준 in vector space model

    - Euclidean distance

    - Angle

- **In vector space model, query-document match score의 기준은 angle, 그 중에서도 cosine similarity임**

#### [ Euclidean distance ]

- 거리로 계산

- 거리가 가까울 수록 유사도 높음

- 안 좋음!

- query와 document의 유사도가 가장 높은 데도 불구하고, 다른 document보다 거리가 먼 경우가 존재

**→ 해결: angle이용**

#### [ Angle ]

- 각도로 계산

- 각도가 작을 수록 유사도 높음

- ex) d를 copy한 후 두 개를 붙여서 d’를 만듦(길이가 2배, 내용은 같음)

    - 거리 상으로는 꽤 멈

    - but, d와 d’의 각도는 0

- 각도가 0 = maximal similarity

#### [ Cosine similarity ]

- 각도가 작을수록 유사도 증가 → 반비례 관계

- 비례관계로 표현하기 위해 cosine을 이용

- 각도가 작을수록 → consine의 값 증가(0과 90도 사이에서) → 유사도 증가

- 각도는 증가하는 방향으로 document들이 반환

    - 즉, 각도가 작은 것부터 result로 반환

- cosine은 감소하는 방향으로 document들이 반환

    - 즉, cosine의 값이 큰 것부터 result로 반환

- cos(q,d)

![image](https://github.com/dareunk/dareunk.github.io/assets/83913407/ab1c98af-b928-4032-909e-a857420da304)

- cos similarity 계산하는 방법 → 과정만 다를 뿐, 결과 값은 동일함

    - 1) 먼저 내적을 계산한 후 내적과 각 vector의 크기의 곱을 나눔

    - 2) 벡터를 크기로 나눠, 단위벡터 구한 후 이 단위벡터들 끼리 내적 ( 이것이 더 편리)

        - 단위벡터: 길이가 1인 vector

- 이때의 vector들은 tf-idf값으로 이루어짐

#### [기초 지식]

- 내적을 계산 → scalar(값)

- 각 vector의 크기는 scalar

- vector을 각 크기로 나눠 구한 단위벡터는 vector

#### [ Consine Similarity 계산 예시 ]

![image](https://github.com/dareunk/dareunk.github.io/assets/83913407/1428f318-eaea-4f53-a0a1-69c5506af809)